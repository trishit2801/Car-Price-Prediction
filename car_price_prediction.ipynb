{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooperative-newton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "alive-thriller",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-alignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "pharmaceutical-photograph",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     model  year  price transmission  mileage fuelType  tax   mpg  engineSize\n",
      "0   Fiesta  2017  12000    Automatic    15944   Petrol  150  57.7         1.0\n",
      "1    Focus  2018  14000       Manual     9083   Petrol  150  57.7         1.0\n",
      "2    Focus  2017  13000       Manual    12456   Petrol  150  57.7         1.0\n",
      "3   Fiesta  2019  17500       Manual    10460   Petrol  145  40.3         1.5\n",
      "4   Fiesta  2019  16500    Automatic     1482   Petrol  145  48.7         1.0\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('ford.csv')\n",
    "print(dataset.head())\n",
    "X = dataset.iloc[:, [0,1,3,4,5,6,7,8]].values\n",
    "y = dataset.iloc[:, 2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "wicked-environment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[' Fiesta' 2017 'Automatic' ... 150 57.7 1.0]\n",
      " [' Focus' 2018 'Manual' ... 150 57.7 1.0]\n",
      " [' Focus' 2017 'Manual' ... 150 57.7 1.0]\n",
      " ...\n",
      " [' B-MAX' 2014 'Manual' ... 30 57.7 1.0]\n",
      " [' Focus' 2015 'Manual' ... 20 67.3 1.6]\n",
      " [' KA' 2018 'Manual' ... 145 57.7 1.2]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "vanilla-hunter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12000 14000 13000 ...  7499  9999  8299]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "professional-triumph",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adjusted-launch",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "X[:,0] = le.fit_transform(X[:,0])\n",
    "X[:,2] = le.fit_transform(X[:,2])\n",
    "X[:,4] = le.fit_transform(X[:,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-receptor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "handy-chess",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dental-secretariat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 2018 1 ... 150 88.3 1.5]\n",
      " [14 2015 1 ... 145 48.7 1.5]\n",
      " [6 2019 0 ... 145 74.3 1.5]\n",
      " ...\n",
      " [6 2018 1 ... 145 60.1 1.0]\n",
      " [2 2019 1 ... 145 53.3 1.0]\n",
      " [6 2016 2 ... 125 51.4 1.0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "severe-tobacco",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14 2017 1 ... 145 48.7 1.5]\n",
      " [14 2014 1 ... 30 61.4 2.0]\n",
      " [5 2010 1 ... 20 68.9 1.6]\n",
      " ...\n",
      " [6 2011 0 ... 205 42.2 1.6]\n",
      " [5 2019 1 ... 145 58.9 1.0]\n",
      " [5 2018 1 ... 150 65.7 1.0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "outstanding-cheese",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10995 12950 17699 ... 11250 15990 10998]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "average-movie",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11298  8995  4750 ...  3995 14320 11999]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resistant-sandwich",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling by Standardisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "equivalent-remedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(len(y_train),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "sapphire-action",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.reshape(len(y_test),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "indoor-logic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10995]\n",
      " [12950]\n",
      " [17699]\n",
      " ...\n",
      " [11250]\n",
      " [15990]\n",
      " [10998]]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "basic-batch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11298]\n",
      " [ 8995]\n",
      " [ 4750]\n",
      " ...\n",
      " [ 3995]\n",
      " [14320]\n",
      " [11999]]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "final-monroe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tfdeeplearning/lib/python3.6/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/opt/anaconda3/envs/tfdeeplearning/lib/python3.6/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "sc_y = StandardScaler()\n",
    "X_train[:,[0,1,3,4,5,6,7]] = sc_X.fit_transform(X_train[:,[0,1,3,4,5,6,7]])\n",
    "X_test[:,[0,1,3,4,5,6,7]] = sc_X.fit_transform(X_test[:,[0,1,3,4,5,6,7]])\n",
    "y_train = sc_y.fit_transform(y_train)\n",
    "y_test = sc_y.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "warming-haiti",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.46394105477514297 0.5489912031502555 1 ... 0.5899303103447131\n",
      "  2.973127184449955 0.34899175902482427]\n",
      " [1.7752323613836323 -0.9082706767381422 1 ... 0.509516041645759\n",
      "  -0.9035456029032669 0.34899175902482427]\n",
      " [-0.21514400853527904 1.0347451631130549 0 ... 0.509516041645759\n",
      "  1.6025863000321492 0.34899175902482427]\n",
      " ...\n",
      " [-0.21514400853527904 0.5489912031502555 1 ... 0.509516041645759\n",
      "  0.21246626012266073 -0.8166390940322924]\n",
      " [-1.2103321934947346 1.0347451631130549 1 ... 0.509516041645759\n",
      "  -0.45322502659455977 -0.8166390940322924]\n",
      " [-0.21514400853527904 -0.42251671677534297 2 ... 0.187858966849943\n",
      "  -0.6392270037655475 -0.8166390940322924]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "informative-radar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.8162368021285207 0.07260172725802629 1 ... 0.5153460508883777\n",
      "  -0.9340440228689167 0.32994566237698625]\n",
      " [1.8162368021285207 -1.4151815771420586 1 ... -1.3598546139596979\n",
      "  0.3671837731162166 1.4517234490163815]\n",
      " [-0.44754863845234466 -3.398892649675505 1 ... -1.5229155413377913\n",
      "  1.1356253849184617 0.5543012197048656]\n",
      " ...\n",
      " [-0.19601692283224853 -2.9029648815421436 0 ... 1.4937116151569387\n",
      "  -1.6000267530975285 0.5543012197048656]\n",
      " [-0.44754863845234466 1.0644572635247496 1 ... 0.5153460508883777\n",
      "  0.11103656918213514 -0.7918321242624091]\n",
      " [-0.44754863845234466 0.568529495391388 1 ... 0.5968765145774244\n",
      "  0.8077569638828371 -0.7918321242624091]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fourth-semiconductor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.27184711]\n",
      " [ 0.13935042]\n",
      " [ 1.13821335]\n",
      " ...\n",
      " [-0.21821265]\n",
      " [ 0.77875731]\n",
      " [-0.27121612]]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "impossible-boutique",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.20283041]\n",
      " [-0.69407075]\n",
      " [-1.5995485 ]\n",
      " ...\n",
      " [-1.76059343]\n",
      " [ 0.44177589]\n",
      " [-0.05330393]]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "comparative-assembly",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the Random Forest model on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "separated-enclosure",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tfdeeplearning/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "/opt/anaconda3/envs/tfdeeplearning/lib/python3.6/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators = 10) # taking no. of trees as 10\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-cheese",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d61165a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = sc_y.inverse_transform(regressor.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4cfdea63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10246.66613629  7649.93697167  3144.52713147 ...  5370.65771632\n",
      " 14466.87025137 11302.50293216]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handmade-privacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting a new result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "little-treasury",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Price:  [23223.28627705]\n"
     ]
    }
   ],
   "source": [
    "model = 'Fiesta'\n",
    "year = 2018\n",
    "transmission = 'Manual'\n",
    "mileage = 13500\n",
    "fuel = 'Petrol'\n",
    "tax = 130\n",
    "mpg = 52.3\n",
    "engine = 1.5\n",
    "predicted_price = sc_y.inverse_transform(regressor.predict([[5,year,1,mileage,4,tax,mpg,engine]]))\n",
    "print('Predicted Price: ', predicted_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-guatemala",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the Trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "certified-chicken",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle_out = open(\"regressor_model.pkl\", \"wb\")\n",
    "pickle.dump(regressor, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "french-league",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ecedf427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9145552216526944"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(sc_y.inverse_transform(y_test), y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78f40ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
